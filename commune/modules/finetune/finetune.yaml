model: robertmyers/targon-7b
dataset:
  path: Anthropic/hh-rlhf
  split: train

device: cuda
max_length: 1000
tag: null
train: true
save_interval: 50  # Save every 50 steps. You can change this number as needed.
quantize:
  mode: bnb
  enabled: true
  config:
    load_in_4bit: True
    bnb_4bit_use_double_quant: True
    bnb_4bit_quant_type: nf4
    bnb_4bit_compute_dtype: torch.bfloat16
    pretraining_tp: 1

trainer:
  dataset_text_field: chosen
  task_type: CAUSAL_LM
  args:
    per_device_train_batch_size: 4
    gradient_accumulation_steps: 4
    output_dir: "{tag}"
    learning_rate: 0.0002
    logging_steps: 100
    max_steps: 500
  max_seq_length: 1000
  lora:
    r: 64
    lora_alpha: 16
    lora_dropout: 0.1
    bias: "none"
    task_type: CAUSAL_LM
