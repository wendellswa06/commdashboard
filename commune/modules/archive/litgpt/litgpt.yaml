
num_samples: 1
model: vicuna.7b
max_new_tokens: 50
top_k: 200
temperature: 0.8
quantize: gptq.int4
strategy: auto
devices: 1
precision: bf16-true
seed: 42
float32_matmul_precision: high
test: false
